{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7374daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 1: Imports y configuraciÃ³n ===\n",
    "from pathlib import Path\n",
    "import os, re, warnings\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc7a1bc-8efe-4815-a197-828e0bf3b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Ciclo</th>\n",
       "      <th>Ruta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region      Ciclo                                               Ruta\n",
       "0  Cajeme  2010-2011  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "1  Cajeme  2011-2012  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "2  Cajeme  2012-2013  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "3  Cajeme  2013-2014  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "4  Cajeme  2014-2015  /lustre/home/mvalenzuela/Workspace/DataAqua-da..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Celda 2: Rutas, mapeo y utilidades ===\n",
    "\n",
    "# Detectar base segÃºn entorno: cluster o local\n",
    "RUTA_BASE = Path(\n",
    "    os.getenv(\"DATAAQUA_BASE\", \"/lustre/home/mvalenzuela/Workspace/DataAqua-dashboard\")\n",
    ")\n",
    "if not RUTA_BASE.exists():\n",
    "    # fallback si no estÃ¡ en el cluster, usar la carpeta actual (tu PC local)\n",
    "    RUTA_BASE = Path(\".\").resolve()\n",
    "\n",
    "# Carpeta de datos relativa al repo\n",
    "RUTA_SALIDA_UNISON = RUTA_BASE / \"data\" / \"Salidas_ETo12_con_uac_y_hh\" / \"Periodo de Cultivo ETo\"\n",
    "\n",
    "# Carpeta de salida de reportes PDF\n",
    "RUTA_REPORTES = RUTA_BASE / \"reports\" / \"modelos\"\n",
    "RUTA_REPORTES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mapeo de columnas (igual al del dashboard, aÃ±adiendo UAC/HH)\n",
    "MAP_UNISON = {\n",
    "    \"AÃ±o_ (YEAR)\": \"Year\", \"AÃƒÂ±o_ (YEAR)\": \"Year\",\n",
    "    \"DÃ­a (DOY)\": \"DOY\",   \"DÃƒÂ­a (DOY)\": \"DOY\",\n",
    "    \"Tmax (T2M_MAX)\": \"Tmax\", \"Tmin (T2M_MIN)\": \"Tmin\",\n",
    "    \"HR (RH2M)\": \"HR\", \"Ux (WS2M)\": \"Ux\",\n",
    "    \"Rs (ALLSKY_SFC_SW_DWN)\": \"Rs\",\n",
    "    \"Rl_ (ALLSKY_SFC_LW_DWN)\": \"Rl\",\n",
    "    \"Ptot_ (PRECTOTCORR)\": \"Ptot\",\n",
    "    \"Pef_\": \"Pef\", \"Tmean_\": \"Tmean\", \"es_\": \"es\", \"ea_\": \"ea\",\n",
    "    \"delta_\": \"delta\", \"P_\": \"P\", \"gamma_\": \"gamma\",\n",
    "    \"Rns_\": \"Rns\", \"Rnl_\": \"Rnl\", \"Rn_\": \"Rn\", \"Rso_\": \"Rso\",\n",
    "    \"Kc_\": \"Kc\", \"decada_\": \"decada\",\n",
    "    \"ET0\": \"ET0\", \"ETc\": \"ETc\", \"ETverde\": \"ETverde\", \"ETazul\": \"ETazul\",\n",
    "    \"Year\": \"Year\", \"DOY\": \"DOY\", \"Dia\": \"Dia\",\n",
    "    \"UACverde_m3_ha\": \"UACverde_m3_ha\",\n",
    "    \"UACazul_m3_ha\": \"UACazul_m3_ha\",\n",
    "    \"HHverde_m3_ton\": \"HHverde_m3_ton\",\n",
    "    \"HHazul_m3_ton\": \"HHazul_m3_ton\",\n",
    "}\n",
    "\n",
    "COLUMNAS_NUM = [\n",
    "    \"Year\",\"DOY\",\"ET0\",\"ETc\",\"ETverde\",\"ETazul\",\"Pef\",\"decada\",\n",
    "    \"Rns\",\"Rnl\",\"Rs\",\"Tmean\",\"HR\",\"Ux\",\"Kc\",\"Tmax\",\"Tmin\",\n",
    "    \"UACverde_m3_ha\",\"UACazul_m3_ha\",\"HHverde_m3_ton\",\"HHazul_m3_ton\"\n",
    "]\n",
    "\n",
    "def _year_doy_to_date(y, doy):\n",
    "    try:\n",
    "        base = datetime(int(y), 1, 1)\n",
    "        return base + timedelta(days=int(doy) - 1)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def leer_y_normalizar(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    last_err = None\n",
    "    for enc in (\"utf-8\",\"latin-1\"):\n",
    "        try:\n",
    "            df = pd.read_csv(p, encoding=enc)\n",
    "            last_err = None\n",
    "            break\n",
    "        except UnicodeDecodeError as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err is not None:\n",
    "        df = pd.read_csv(p)\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df = df.rename(columns=lambda c: MAP_UNISON.get(c, c))\n",
    "\n",
    "    # si no existe 'DÃ­a' y tenemos DOY, crea 'DÃ­a' para compatibilidad con la libreta\n",
    "    if \"DÃ­a\" not in df.columns and \"DOY\" in df.columns:\n",
    "        df[\"DÃ­a\"] = pd.to_numeric(df[\"DOY\"], errors=\"coerce\")\n",
    "\n",
    "    for c in set(COLUMNAS_NUM).intersection(df.columns):\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Fecha y DÃ­a de ciclo (opcional)\n",
    "    if {\"Year\",\"DOY\"}.issubset(df.columns):\n",
    "        fechas = [_year_doy_to_date(y,d) for y,d in zip(df[\"Year\"], df[\"DOY\"])]\n",
    "        df[\"Fecha\"] = pd.to_datetime(fechas)\n",
    "        if df[\"Fecha\"].notna().any():\n",
    "            f0 = df[\"Fecha\"].dropna().iloc[0]\n",
    "            df[\"Dia_ciclo\"] = (df[\"Fecha\"] - f0).dt.days.astype(\"Int64\")\n",
    "        else:\n",
    "            df[\"Dia_ciclo\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "    else:\n",
    "        df[\"Fecha\"] = pd.NaT\n",
    "        df[\"Dia_ciclo\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def parse_unison_filename(filename: str):\n",
    "    m = re.match(r\"([A-Za-zÃÃ‰ÃÃ“ÃšÃ¡Ã©Ã­Ã³ÃºÃ±Ã‘\\s]+)-FAO56-(\\d{4})(?:-(\\d{4}))?-SALIDA\\.csv$\", filename, re.I)\n",
    "    if not m: return None, None\n",
    "    reg, y1, y2 = m.groups()\n",
    "    if reg == \"VillaAllende\": reg = \"Villa de Allende\"\n",
    "    if reg == \"Etchhojoa\":    reg = \"Etchojoa\"\n",
    "    ciclo = y1 if not y2 else f\"{y1}-{y2}\"\n",
    "    return reg.strip(), ciclo\n",
    "\n",
    "def construir_catalogo(base_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if not base_dir.exists():\n",
    "        return pd.DataFrame(columns=[\"Region\",\"Ciclo\",\"Ruta\"])\n",
    "    for reg_folder in sorted(os.listdir(base_dir)):\n",
    "        d = base_dir / reg_folder\n",
    "        if not d.is_dir(): continue\n",
    "        for f in sorted(os.listdir(d)):\n",
    "            if not f.lower().endswith(\".csv\"): continue\n",
    "            reg, ciclo = parse_unison_filename(f)\n",
    "            if reg and ciclo:\n",
    "                rows.append({\"Region\": reg, \"Ciclo\": ciclo, \"Ruta\": str(d / f)})\n",
    "    return pd.DataFrame(rows).sort_values([\"Region\",\"Ciclo\"]).reset_index(drop=True)\n",
    "\n",
    "CAT = construir_catalogo(RUTA_SALIDA_UNISON)\n",
    "display(CAT.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fd9b9d-a8f5-4d6e-b536-678d1d3a3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 3: Capturador de figuras y helpers PDF ===\n",
    "\n",
    "class FiguraCapture:\n",
    "    \"\"\"\n",
    "    Captura TODAS las figuras nuevas creadas por matplotlib mientras se ejecuta el bloque del profesor.\n",
    "    \"\"\"\n",
    "    def __enter__(self):\n",
    "        self._before = set(plt.get_fignums())\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        self.figs = []\n",
    "        after = set(plt.get_fignums())\n",
    "        new_ids = sorted(list(after - self._before))\n",
    "        for fid in new_ids:\n",
    "            fig = plt.figure(fid)\n",
    "            self.figs.append(fig)\n",
    "\n",
    "def add_plotly_fig_as_matplotlib(fig):\n",
    "    \"\"\"\n",
    "    Convierte un fig de Plotly a imagen (PNG) usando kaleido y lo mete en una Figure de matplotlib\n",
    "    para poder guardarlo en el PDF.\n",
    "    \"\"\"\n",
    "    buf = pio.to_image(fig, format=\"png\", scale=2)  # requiere `kaleido`\n",
    "    bio = BytesIO(buf)\n",
    "    img = mpimg.imread(bio, format='png')\n",
    "    mfig = plt.figure(figsize=(12,6))\n",
    "    ax = mfig.add_subplot(111)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    return mfig\n",
    "\n",
    "def pagina_portada(pdf: PdfPages, region: str, ciclos: list):\n",
    "    fig = plt.figure(figsize=(12,7)); plt.axis('off')\n",
    "    titulo = f\"Reporte de Modelos â€” {region}\"\n",
    "    subt = \"Ciclos incluidos: \" + \", \".join(ciclos)\n",
    "    plt.text(0.5, 0.65, titulo, ha='center', va='center', fontsize=24, weight='bold')\n",
    "    plt.text(0.5, 0.45, subt,   ha='center', va='center', fontsize=12)\n",
    "    plt.text(0.5, 0.15, f\"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "             ha='center', va='center', fontsize=10, alpha=0.7)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "def kpis_basicos(df: pd.DataFrame) -> dict:\n",
    "    mask = df[\"ETc\"].notna() if \"ETc\" in df else pd.Series(False, index=df.index)\n",
    "    dias = int(mask.sum())\n",
    "    etc_total = float(df.loc[mask, \"ETc\"].sum())     if \"ETc\"     in df else np.nan\n",
    "    etv_total = float(df.loc[mask, \"ETverde\"].sum()) if \"ETverde\" in df else np.nan\n",
    "    eta_total = float(df.loc[mask, \"ETazul\"].sum())  if \"ETazul\"  in df else np.nan\n",
    "    tmax = float(df[\"Tmax\"].max()) if \"Tmax\" in df else np.nan\n",
    "    tmin = float(df[\"Tmin\"].min()) if \"Tmin\" in df else np.nan\n",
    "    return {\"dias\":dias,\"etc_total\":etc_total,\"etv_total\":etv_total,\"eta_total\":eta_total,\"tmax\":tmax,\"tmin\":tmin}\n",
    "\n",
    "def pagina_kpis(pdf: PdfPages, region: str, ciclo: str, df: pd.DataFrame):\n",
    "    k = kpis_basicos(df)\n",
    "    fig, ax = plt.subplots(figsize=(12,6)); ax.axis('off')\n",
    "    ax.text(0.02, 0.95, f\"{region} â€” {ciclo}\", fontsize=16, weight='bold')\n",
    "    lines = [\n",
    "        f\"DÃ­as del ciclo: {k['dias']}\",\n",
    "        f\"ETc total [mm]: {k['etc_total']:.1f}\" if not np.isnan(k['etc_total']) else \"ETc total: â€”\",\n",
    "        f\"ETverde total [mm]: {k['etv_total']:.1f}\" if not np.isnan(k['etv_total']) else \"ETverde total: â€”\",\n",
    "        f\"ETazul total [mm]: {k['eta_total']:.1f}\" if not np.isnan(k['eta_total']) else \"ETazul total: â€”\",\n",
    "        f\"Tmax / Tmin [Â°C]: {k['tmax']:.1f} / {k['tmin']:.1f}\" if not np.isnan(k['tmax']) else \"Tmax/Tmin: â€”\",\n",
    "    ]\n",
    "    for i, L in enumerate(lines):\n",
    "        ax.text(0.05, 0.8 - 0.1*i, L, fontsize=12)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "def anexar_figuras(pdf: PdfPages, figs: list, titulo_encabezado: str = None):\n",
    "    if titulo_encabezado:\n",
    "        fig = plt.figure(figsize=(12,1.2)); plt.axis('off')\n",
    "        plt.text(0.02, 0.5, titulo_encabezado, va='center', fontsize=14, weight='bold')\n",
    "        pdf.savefig(fig); plt.close(fig)\n",
    "    for f in figs:\n",
    "        pdf.savefig(f); plt.close(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b71313c-570e-462b-8ff4-ced1cc776951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 4: BLOQUE DEL PROFESOR (integrado) ===\n",
    "def correr_bloques_profesor(df: pd.DataFrame, region: str, ciclo: str):\n",
    "    \"\"\"\n",
    "    Replicamos la libreta del profesor, usando 'df' ya cargado/normalizado.\n",
    "    Se generan las mismas figuras. Las de Plotly se exportan a imagen para meterlas al PDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    logs = []   # <--- agrega esta lÃ­nea\n",
    "\n",
    "    # ---------- CorrelaciÃ³n ----------\n",
    "    variables = ['Tmax', 'Tmin', 'Tmean', 'HR', 'Ux', 'Rs', 'ET0', 'ETc']\n",
    "    df_selected = df[[v for v in variables if v in df.columns]].dropna()\n",
    "    if not df_selected.empty and df_selected.shape[1] >= 2:\n",
    "        corr_matrix = df_selected.corr()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        mask = np.triu(np.ones_like(corr_matrix))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='viridis', fmt=\".2f\", square=True, mask=mask)\n",
    "        plt.title(\"Matriz de CorrelaciÃ³n entre Variables MeteorolÃ³gicas\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # ---------- DispersiÃ³n (Tmax, Rs, HR, Ux) vs ET0; ET0 vs ETc ----------\n",
    "    variables_disp = [c for c in ['Tmax','HR','Ux','Rs','ET0','ETc'] if c in df.columns]\n",
    "    if all(c in df.columns for c in ['Tmax','HR','Ux','Rs','ET0']) or 'ETc' in df.columns:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = np.array(axes)\n",
    "        # guardas para no explotar si falta algo\n",
    "        try:\n",
    "            if 'Tmax' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Tmax', y='ET0', data=df, ax=axes[0, 0], color='blue')\n",
    "                axes[0, 0].set_title('Tmax vs ET0')\n",
    "            if 'Rs' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Rs', y='ET0', data=df, ax=axes[0, 1], color='green')\n",
    "                axes[0, 1].set_title('Rs vs ET0')\n",
    "            if 'HR' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='HR', y='ET0', data=df, ax=axes[0, 2], color='red')\n",
    "                axes[0, 2].set_title('HR vs ET0')\n",
    "            if 'Ux' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Ux', y='ET0', data=df, ax=axes[1, 0], color='purple')\n",
    "                axes[1, 0].set_title('Ux vs ET0')\n",
    "            if 'ET0' in df and 'ETc' in df:\n",
    "                sns.scatterplot(x='ET0', y='ETc', data=df, ax=axes[1, 1], color='orange')\n",
    "                axes[1, 1].set_title('ET0 vs ETc')\n",
    "            # elimina el Ãºltimo si sobra\n",
    "            try:\n",
    "                fig.delaxes(axes[1, 2])\n",
    "            except Exception:\n",
    "                pass\n",
    "            fig.suptitle(f\"DispersiÃ³n â€” {region} ({ciclo})\")\n",
    "            fig.tight_layout()\n",
    "        except Exception:\n",
    "            plt.close(fig)\n",
    "\n",
    "    # ---------- RegresiÃ³n Lineal para ET0 ----------\n",
    "    features = [c for c in ['Tmax','Tmin','HR','Ux','Rs'] if c in df.columns]\n",
    "    target = 'ET0'\n",
    "    if target in df.columns and len(features) >= 2:\n",
    "        df_model = df[features + [target]].dropna()\n",
    "        if not df_model.empty:\n",
    "            X = df_model[features]\n",
    "            y = df_model[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            #print(f\"[{region} {ciclo}] RegresiÃ³n Lineal ET0 â€” RÂ²: {r2:.4f}  MSE: {mse:.4f}\")\n",
    "            \n",
    "            logs.append(f\"[{region} {ciclo}] RegresiÃ³n Lineal ET0 â€” RÂ²: {r2:.4f}  MSE: {mse:.4f}\")\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.scatterplot(x=y_test, y=y_pred)\n",
    "            lim_min = min(y_test.min(), y_pred.min())\n",
    "            lim_max = max(y_test.max(), y_pred.max())\n",
    "            plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--')\n",
    "            plt.xlabel('ET0 Real')\n",
    "            plt.ylabel('ET0 Predicho')\n",
    "            plt.title(f\"ComparaciÃ³n entre ET0 Real y Predicho â€” {region} ({ciclo})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "    # ---------- Random Forest para ET0 ----------\n",
    "    if target in df.columns and len(features) >= 2:\n",
    "        df_rf = df[features + [target]].dropna()\n",
    "        if not df_rf.empty:\n",
    "            X = df_rf[features]\n",
    "            y = df_rf[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "\n",
    "            r2_rf = r2_score(y_test, y_pred)\n",
    "            mse_rf = mean_squared_error(y_test, y_pred)\n",
    "            #print(f\"[{region} {ciclo}] Random Forest ET0 â€” RÂ²: {r2_rf:.4f}  MSE: {mse_rf:.4f}\")\n",
    "            #print(f\"Importancias: {dict(zip(features, rf.feature_importances_))}\")\n",
    "\n",
    "            logs.append(f\"[{region} {ciclo}] Random Forest ET0 â€” RÂ²: {r2_rf:.4f}  MSE: {mse_rf:.4f}\")\n",
    "            logs.append(f\"Importancias: {dict(zip(features, rf.feature_importances_))}\")\n",
    "\n",
    "            # Importancias (barras)\n",
    "            imp_series = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "            plt.figure(figsize=(8,4))\n",
    "            imp_series.plot(kind='bar')\n",
    "            plt.title(f\"Importancia de variables (RF) â€” {region} ({ciclo})\")\n",
    "            plt.ylabel(\"Importancia\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "    # ---------- Agrupamientos (KMeans) con meteo ----------\n",
    "    meteo_cols = [c for c in ['Tmax','Tmin','HR','Ux','Rs'] if c in df.columns]\n",
    "    Xmet = df[meteo_cols].dropna() if meteo_cols else pd.DataFrame()\n",
    "    if not Xmet.empty and Xmet.shape[1] >= 2:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(Xmet)\n",
    "\n",
    "        # mÃ©todo del codo\n",
    "        inertia = []\n",
    "        ks = list(range(2, 10))\n",
    "        for k in ks:\n",
    "            km = KMeans(n_clusters=k, random_state=42)\n",
    "            km.fit(X_scaled)\n",
    "            inertia.append(km.inertia_)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.plot(ks, inertia, marker='o')\n",
    "        plt.title(\"MÃ©todo del codo\")\n",
    "        plt.xlabel(\"NÃºmero de clÃºsteres\")\n",
    "        plt.ylabel(\"Inercia\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        k_final = 5\n",
    "        km = KMeans(n_clusters=k_final, random_state=42)\n",
    "        df['Grupo'] = km.fit_predict(X_scaled)\n",
    "\n",
    "        if 'Tmax' in df and 'Rs' in df and 'Grupo' in df:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            sns.scatterplot(data=df, x='Tmax', y='Rs', hue='Grupo', palette='Set2')\n",
    "            plt.title(f\"ClasificaciÃ³n de dÃ­as climÃ¡ticos â€” {region} ({ciclo})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "        # DÃ­as por grupo\n",
    "        if 'DÃ­a' in df and 'Grupo' in df:\n",
    "            # pares (grupo, dÃ­a)\n",
    "            dias_por_grupo = { k: df[df['Grupo'] == k]['DÃ­a'].dropna().astype(int).tolist()\n",
    "                               for k in sorted(df['Grupo'].dropna().unique()) }\n",
    "            filas = [(g, d) for g, dias in dias_por_grupo.items() for d in dias]\n",
    "            df_dias = pd.DataFrame(filas, columns=['Grupo','DÃ­a'])\n",
    "            df['grupo_index'] = df.groupby('Grupo').cumcount()\n",
    "            df_dias['grupo_index'] = df_dias.groupby('Grupo').cumcount()\n",
    "            df_grupos = df.merge(df_dias, on=['Grupo','grupo_index'], how='left').drop(columns=['grupo_index'])\n",
    "\n",
    "            # scatter DÃ­a vs Grupo\n",
    "            plot_df_grupos = df_grupos[['DÃ­a_y','Grupo']].dropna()\n",
    "            if not plot_df_grupos.empty:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                sns.scatterplot(data=plot_df_grupos, x='DÃ­a_y', y='Grupo', hue='Grupo', palette='Set2')\n",
    "                plt.title(f'DistribuciÃ³n de dÃ­as por grupo â€” {region} ({ciclo})')\n",
    "                plt.xlabel('DÃ­a del aÃ±o'); plt.ylabel('Grupo')\n",
    "                plt.tight_layout()\n",
    "\n",
    "            # ---------- Boxplots con Plotly por dÃ©cada/variable/Grupo ----------\n",
    "            # Si existen columnas necesarias:\n",
    "            if 'decada' in df_grupos.columns:\n",
    "                # variables para box (usa meteo_cols si existen)\n",
    "                for var in meteo_cols:\n",
    "                    try:\n",
    "                        figpx = px.box(\n",
    "                            df_grupos.dropna(subset=['decada', var, 'Grupo']),\n",
    "                            x='decada', y=var, color='Grupo',\n",
    "                            title=f'{var} por grupo y dÃ©cada â€” {region} ({ciclo})',\n",
    "                            labels={'decada':'DÃ©cada', var:var, 'Grupo':'Grupo'},\n",
    "                            color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "                            points='all'\n",
    "                        )\n",
    "                        figpx.update_layout(boxmode='group', legend_title='Grupo', template='plotly_white')\n",
    "                        # exportar a imagen y agregar al PDF\n",
    "                        mfig = add_plotly_fig_as_matplotlib(figpx)\n",
    "                        plt.close(mfig)\n",
    "                        # NOTA: no se aÃ±ade aquÃ­; el capturador solo recoge matplotlib generadas en esta funciÃ³n.\n",
    "                        # Para asegurarnos de que entren al PDF, mostramos la figura matplotlib creada:\n",
    "                        mfig = add_plotly_fig_as_matplotlib(figpx)\n",
    "                        plt.show()  # se registra en la lista de matplotlib\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    # ---------- Clusters agregando ET0 y ETc ----------\n",
    "    vars2 = [c for c in ['Tmax','Tmin','HR','Ux','Rs','ET0','ETc'] if c in df.columns]\n",
    "    if len(vars2) >= 3:\n",
    "        df1 = df.copy()\n",
    "        data = df1[vars2].dropna()\n",
    "        if not data.empty:\n",
    "            scaler = StandardScaler()\n",
    "            data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "            kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "            df1['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "            # estadÃ­sticas descriptivas (solo imprime)\n",
    "            stats = df1.groupby('cluster')[vars2].agg(['mean'])\n",
    "            #print(\"EstadÃ­sticas descriptivas por grupo:\")\n",
    "            #print(stats)\n",
    "\n",
    "            logs.append(\"EstadÃ­sticas descriptivas por grupo (medias):\")\n",
    "            logs.append(stats.to_string())\n",
    "            \n",
    "            # boxplots (seaborn) por variable\n",
    "            n = len(vars2)\n",
    "            nrows = int(np.ceil((n)/2))\n",
    "            ncols = 2\n",
    "            fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 4*nrows))\n",
    "            axes = np.array(axes).reshape(nrows, ncols)\n",
    "            idx = 0\n",
    "            for r in range(nrows):\n",
    "                for c in range(ncols):\n",
    "                    if idx < n:\n",
    "                        var = vars2[idx]\n",
    "                        sns.boxplot(x='cluster', y=var, data=df1, ax=axes[r, c], palette='Set1')\n",
    "                        axes[r, c].set_title(f'DistribuciÃ³n de {var} por grupo', fontsize=12)\n",
    "                        axes[r, c].set_xlabel('Grupo'); axes[r, c].set_ylabel(var)\n",
    "                        idx += 1\n",
    "                    else:\n",
    "                        axes[r, c].set_visible(False)\n",
    "            fig.suptitle(f\"Boxplots por grupo â€” {region} ({ciclo})\")\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # otro KMeans a 5 clÃºsteres (como en la libreta)\n",
    "            k_final = 5\n",
    "            km = KMeans(n_clusters=k_final, random_state=42)\n",
    "            df1['Grupo'] = km.fit_predict(data_scaled)\n",
    "\n",
    "            if 'Tmax' in df1 and 'Rs' in df1:\n",
    "                plt.figure(figsize=(7,5))\n",
    "                sns.scatterplot(data=df1, x='Tmax', y='Rs', hue='Grupo', palette='Set1')\n",
    "                plt.title(f\"ClasificaciÃ³n de dÃ­as climÃ¡ticos (ET0/ETc incluidos) â€” {region} ({ciclo})\")\n",
    "                plt.tight_layout()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a96aa4-467c-4887-be99-125688f009c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Generando PDF para Cajeme: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Cajeme_model_report.pdf\n",
      "   â–¸ Procesando Cajeme â€” 2010-2011\n",
      "   â–¸ Procesando Cajeme â€” 2011-2012\n",
      "   â–¸ Procesando Cajeme â€” 2012-2013\n",
      "   â–¸ Procesando Cajeme â€” 2013-2014\n",
      "   â–¸ Procesando Cajeme â€” 2014-2015\n",
      "   â–¸ Procesando Cajeme â€” 2015-2016\n",
      "   â–¸ Procesando Cajeme â€” 2016-2017\n",
      "   â–¸ Procesando Cajeme â€” 2017-2018\n",
      "   â–¸ Procesando Cajeme â€” 2018-2019\n",
      "   â–¸ Procesando Cajeme â€” 2019-2020\n",
      "   â–¸ Procesando Cajeme â€” 2020-2021\n",
      "   â–¸ Procesando Cajeme â€” 2021-2022\n",
      "   â–¸ Procesando Cajeme â€” 2022-2023\n",
      "   â–¸ Procesando Cajeme â€” 2023-2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Cajeme_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Ensenada: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Ensenada_model_report.pdf\n",
      "   â–¸ Procesando Ensenada â€” 2010-2011\n",
      "   â–¸ Procesando Ensenada â€” 2011-2012\n",
      "   â–¸ Procesando Ensenada â€” 2012-2013\n",
      "   â–¸ Procesando Ensenada â€” 2013-2014\n",
      "   â–¸ Procesando Ensenada â€” 2014-2015\n",
      "   â–¸ Procesando Ensenada â€” 2015-2016\n",
      "   â–¸ Procesando Ensenada â€” 2016-2017\n",
      "   â–¸ Procesando Ensenada â€” 2017-2018\n",
      "   â–¸ Procesando Ensenada â€” 2018-2019\n",
      "   â–¸ Procesando Ensenada â€” 2019-2020\n",
      "   â–¸ Procesando Ensenada â€” 2020-2021\n",
      "   â–¸ Procesando Ensenada â€” 2021-2022\n",
      "   â–¸ Procesando Ensenada â€” 2022-2023\n",
      "   â–¸ Procesando Ensenada â€” 2023-2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Ensenada_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Etchojoa: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Etchojoa_model_report.pdf\n",
      "   â–¸ Procesando Etchojoa â€” 2010-2011\n",
      "   â–¸ Procesando Etchojoa â€” 2011-2012\n",
      "   â–¸ Procesando Etchojoa â€” 2012-2013\n",
      "   â–¸ Procesando Etchojoa â€” 2013-2014\n",
      "   â–¸ Procesando Etchojoa â€” 2014-2015\n",
      "   â–¸ Procesando Etchojoa â€” 2015-2016\n",
      "   â–¸ Procesando Etchojoa â€” 2016-2017\n",
      "   â–¸ Procesando Etchojoa â€” 2017-2018\n",
      "   â–¸ Procesando Etchojoa â€” 2018-2019\n",
      "   â–¸ Procesando Etchojoa â€” 2019-2020\n",
      "   â–¸ Procesando Etchojoa â€” 2020-2021\n",
      "   â–¸ Procesando Etchojoa â€” 2021-2022\n",
      "   â–¸ Procesando Etchojoa â€” 2022-2023\n",
      "   â–¸ Procesando Etchojoa â€” 2023-2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Etchojoa_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Metepec: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Metepec_model_report.pdf\n",
      "   â–¸ Procesando Metepec â€” 2010\n",
      "   â–¸ Procesando Metepec â€” 2011\n",
      "   â–¸ Procesando Metepec â€” 2012\n",
      "   â–¸ Procesando Metepec â€” 2013\n",
      "   â–¸ Procesando Metepec â€” 2014\n",
      "   â–¸ Procesando Metepec â€” 2015\n",
      "   â–¸ Procesando Metepec â€” 2016\n",
      "   â–¸ Procesando Metepec â€” 2017\n",
      "   â–¸ Procesando Metepec â€” 2018\n",
      "   â–¸ Procesando Metepec â€” 2019\n",
      "   â–¸ Procesando Metepec â€” 2020\n",
      "   â–¸ Procesando Metepec â€” 2021\n",
      "   â–¸ Procesando Metepec â€” 2022\n",
      "   â–¸ Procesando Metepec â€” 2023\n",
      "   â–¸ Procesando Metepec â€” 2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Metepec_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Toluca: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Toluca_model_report.pdf\n",
      "   â–¸ Procesando Toluca â€” 2010\n",
      "   â–¸ Procesando Toluca â€” 2011\n",
      "   â–¸ Procesando Toluca â€” 2012\n",
      "   â–¸ Procesando Toluca â€” 2013\n",
      "   â–¸ Procesando Toluca â€” 2014\n",
      "   â–¸ Procesando Toluca â€” 2015\n",
      "   â–¸ Procesando Toluca â€” 2016\n",
      "   â–¸ Procesando Toluca â€” 2017\n",
      "   â–¸ Procesando Toluca â€” 2018\n",
      "   â–¸ Procesando Toluca â€” 2019\n",
      "   â–¸ Procesando Toluca â€” 2020\n",
      "   â–¸ Procesando Toluca â€” 2021\n",
      "   â–¸ Procesando Toluca â€” 2022\n",
      "   â–¸ Procesando Toluca â€” 2023\n",
      "   â–¸ Procesando Toluca â€” 2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Toluca_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Villa de Allende: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Villa_de_Allende_model_report.pdf\n",
      "   â–¸ Procesando Villa de Allende â€” 2010\n",
      "   â–¸ Procesando Villa de Allende â€” 2011\n",
      "   â–¸ Procesando Villa de Allende â€” 2012\n",
      "   â–¸ Procesando Villa de Allende â€” 2013\n",
      "   â–¸ Procesando Villa de Allende â€” 2014\n",
      "   â–¸ Procesando Villa de Allende â€” 2015\n",
      "   â–¸ Procesando Villa de Allende â€” 2016\n",
      "   â–¸ Procesando Villa de Allende â€” 2017\n",
      "   â–¸ Procesando Villa de Allende â€” 2018\n",
      "   â–¸ Procesando Villa de Allende â€” 2019\n",
      "   â–¸ Procesando Villa de Allende â€” 2020\n",
      "   â–¸ Procesando Villa de Allende â€” 2021\n",
      "   â–¸ Procesando Villa de Allende â€” 2022\n",
      "   â–¸ Procesando Villa de Allende â€” 2023\n",
      "   â–¸ Procesando Villa de Allende â€” 2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Villa_de_Allende_model_report.pdf\n",
      "\n",
      "ðŸ§¾ Generando PDF para Zapopan: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Zapopan_model_report.pdf\n",
      "   â–¸ Procesando Zapopan â€” 2010\n",
      "   â–¸ Procesando Zapopan â€” 2011\n",
      "   â–¸ Procesando Zapopan â€” 2012\n",
      "   â–¸ Procesando Zapopan â€” 2013\n",
      "   â–¸ Procesando Zapopan â€” 2014\n",
      "   â–¸ Procesando Zapopan â€” 2015\n",
      "   â–¸ Procesando Zapopan â€” 2016\n",
      "   â–¸ Procesando Zapopan â€” 2017\n",
      "   â–¸ Procesando Zapopan â€” 2018\n",
      "   â–¸ Procesando Zapopan â€” 2019\n",
      "   â–¸ Procesando Zapopan â€” 2020\n",
      "   â–¸ Procesando Zapopan â€” 2021\n",
      "   â–¸ Procesando Zapopan â€” 2022\n",
      "   â–¸ Procesando Zapopan â€” 2023\n",
      "   â–¸ Procesando Zapopan â€” 2024\n",
      "âœ… PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Zapopan_model_report.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Celda 5: Proceso por lote (PDF por regiÃ³n con TODAS las figuras del profesor) ===\n",
    "\n",
    "CAT = construir_catalogo(RUTA_SALIDA_UNISON)\n",
    "if CAT.empty:\n",
    "    raise SystemExit(\"No se encontraron archivos en la ruta de datos.\")\n",
    "\n",
    "regiones = sorted(CAT[\"Region\"].unique())\n",
    "for region in regiones:\n",
    "    cat_reg = CAT[CAT[\"Region\"] == region].sort_values(\"Ciclo\")\n",
    "    ciclos = list(cat_reg[\"Ciclo\"].unique())\n",
    "    salida_pdf = RUTA_REPORTES / f\"{region.replace(' ', '_')}_model_report.pdf\"\n",
    "    print(f\"ðŸ§¾ Generando PDF para {region}: {salida_pdf}\")\n",
    "\n",
    "    with PdfPages(salida_pdf) as pdf:\n",
    "        # Portada\n",
    "        pagina_portada(pdf, region, ciclos)\n",
    "\n",
    "        # Por cada ciclo\n",
    "        for ciclo, ruta in cat_reg[[\"Ciclo\",\"Ruta\"]].itertuples(index=False):\n",
    "            print(f\"   â–¸ Procesando {region} â€” {ciclo}\")\n",
    "            df = leer_y_normalizar(ruta)\n",
    "            if df.empty:\n",
    "                print(\"     (sin datos, se omite)\"); continue\n",
    "\n",
    "            # KPI bÃ¡sicos (siempre)\n",
    "            pagina_kpis(pdf, region, ciclo, df)\n",
    "\n",
    "            # Captura TODAS las figuras matplotlib que genere el bloque del profesor\n",
    "            # with FiguraCapture() as cap:\n",
    "            #     correr_bloques_profesor(df, region, ciclo)\n",
    "\n",
    "            # # Agrega todas las figuras capturadas\n",
    "            # if getattr(cap, \"figs\", None):\n",
    "            #     anexar_figuras(pdf, cap.figs, titulo_encabezado=f\"{region} â€” {ciclo}\")\n",
    "\n",
    "            with FiguraCapture() as cap:\n",
    "                logs = correr_bloques_profesor(df, region, ciclo)\n",
    "\n",
    "            # 1) PÃ¡gina de mÃ©tricos/texto (si hay)\n",
    "            if logs:\n",
    "                texto = \"\\n\".join(logs)\n",
    "                fig_txt, ax_txt = plt.subplots(figsize=(12, 7))\n",
    "                ax_txt.axis('off')\n",
    "                ax_txt.text(0.02, 0.98, f\"{region} â€” {ciclo}  Â·  Resultados y mÃ©tricas\", fontsize=14, weight='bold', va='top')\n",
    "                ax_txt.text(0.02, 0.92, texto, fontsize=10, va='top', family='monospace', wrap=True)\n",
    "                pdf.savefig(fig_txt); plt.close(fig_txt)\n",
    "\n",
    "            # 2) Todas las figuras capturadas\n",
    "            if getattr(cap, \"figs\", None):\n",
    "                anexar_figuras(pdf, cap.figs, titulo_encabezado=f\"{region} â€” {ciclo}\")\n",
    "\n",
    "            \n",
    "\n",
    "    print(f\"âœ… PDF guardado: {salida_pdf}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed04f7-d2bf-48c6-89bb-1dccda69fa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beff663-bdef-4cac-8256-670684ce2b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Proyect-Env)",
   "language": "python",
   "name": "proyect-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
